{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjKKBYbl3lA9"
   },
   "source": [
    "## **OpenCV Github Link** https://github.com/opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7R8j-kdo3lA-",
    "outputId": "ddb7de0d-4fe1-4320-99f8-dcbcfcc8cc35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4.0\n"
     ]
    }
   ],
   "source": [
    "import cv2 #Import the OpenCV Library\n",
    "import numpy as np\n",
    "\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJP7dtRb3lBD"
   },
   "source": [
    "### How to read, write, and display Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6R0y_I1P3lBE"
   },
   "outputs": [],
   "source": [
    "#Reading & Displaying an Image\n",
    "\n",
    "img = cv2.imread('yourImage.jpg')\n",
    "#imread enables us to read an Image\n",
    "#The 2nd argumnet is a flag which specifies the way image should be read\n",
    "\n",
    "cv2.imshow(\"Output\", img) #Displaying the Image\n",
    "\n",
    "cv2.waitKey(0) #Delay. No. of Milliseconds for which we want to show our image window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1xln_W2M3lBF",
    "outputId": "44e179fc-3be9-4ae5-88a6-935d2e86d8bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('copy_yourImage.jpg', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHjYEDn63lBG"
   },
   "source": [
    "### How to read, write, and display Videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Av1x-XDP3lBJ"
   },
   "outputs": [],
   "source": [
    "#Reading & Displaying a Video\n",
    "\n",
    "cap = cv2.VideoCapture(0) #If you want to display the Video File, just give the name of it inplace of 0\n",
    "\n",
    "# is a 4-byte identifier which specifies the format of a video stream\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('X','V','I','D')\n",
    "\n",
    "out = cv2.VideoWriter('Name of Output File.avi', fourcc, 20.0, (640,480)) #No. of frames/s, Frame Size\n",
    "\n",
    "#Videos are just a sequence of Images\n",
    "#So, we will add a while loop to capture the frame continuously\n",
    "\n",
    "while True:\n",
    "    success, frame = cap.read() #frame variable will capture the Video & success variable will tell us whether it was captured successfully or not\n",
    "\n",
    "    if success == True:\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "        cv2.imshow(\"Video\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'): #This adds a Delay and looks for the key press inorder to break the loop\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release() #Release the resources after recording\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "benRdYf33lBK"
   },
   "outputs": [],
   "source": [
    "#Reading & Displaying a Video\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cap.set(3, 640)#Width\n",
    "cap.set(4, 480)#Height\n",
    "cap.set(10, 100)#brightness\n",
    "\n",
    "#Videos are just a sequence of Images\n",
    "#So, we will add a while loop to go through each frame\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read() #img variable will capture the Video & success variable will tell us whether it was captured successfully or not\n",
    "    cv2.imshow(\"Video\", img)\n",
    "\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): #This adds a Delay and looks for the key press inorder to break the loop\n",
    "        break\n",
    "\n",
    "cap.release() #Release the resources after recording\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pf8ck8z3lBO"
   },
   "source": [
    "### Basic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XoIKh1mq3lBR"
   },
   "outputs": [],
   "source": [
    "#Converting the Image into Gray Scale\n",
    "\n",
    "#Reading an Image\n",
    "\n",
    "img = cv2.imread('yourImage.jpg')\n",
    "\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)#Converting the Image into Gray Scale\n",
    "\n",
    "cv2.imshow('GrayScale Image',imgGray)\n",
    "\n",
    "cv2.imwrite('copy_lena.png', imgGray)\n",
    "\n",
    "\n",
    "\n",
    "#imgGray1 = cv2.cvtColor(imgGray, cv2.COLOR_GRAY2RGB)#Converting the Image into Gray Scale\n",
    "\n",
    "#cv2.imshow('GrayScale Image1',imgGray1)\n",
    "\n",
    "\n",
    "cv2.waitKey(0) #Delay. No. of Milliseconds for which we want to show our image window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1bLfokqJ3lBS"
   },
   "outputs": [],
   "source": [
    "#Blur Function to Blur the Image\n",
    "\n",
    "#Reading an Image\n",
    "\n",
    "img = cv2.imread('yourImage.jpg')\n",
    "\n",
    "imgBlur = cv2.GaussianBlur(img, (21,21), 0)\n",
    "#(7,7) is the Kernel Size (Amount of Blur) which is always odd. So, (3,3), (5,5), etc.\n",
    "# 0 is Sig function (Standard Deviation along X-Direction)\n",
    "\n",
    "cv2.imshow('Blurred Image',imgBlur)\n",
    "\n",
    "cv2.waitKey(0) #Delay. No. of Milliseconds for which we want to show our image window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EXZhkkmp3lBT"
   },
   "outputs": [],
   "source": [
    "#Edge Detector - Canny\n",
    "\n",
    "img = cv2.imread('yourImage.jpg') #Reading an Image\n",
    "\n",
    "imgCanny = cv2.Canny(img, 150, 200)#Threshold Values\n",
    "\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "#Type of the object which is unsigned integer of 8 bits which means the values can range from 0 to 255\n",
    "\n",
    "imgDilation = cv2.dilate(imgCanny, kernel, iterations = 1)#dilate function is used when the Edges are not properly connected\n",
    "\n",
    "imgErosion = cv2.erode(imgDilation, kernel, iterations = 1)#Erosion function is used when we want to thin (Erode) the Image\n",
    "\n",
    "\n",
    "#iterations - How much thickness do we actually need?\n",
    "\n",
    "cv2.imshow('Canny Image',imgCanny)\n",
    "cv2.imshow('Dilation Image',imgDilation)\n",
    "cv2.imshow('Erosion Image',imgErosion)\n",
    "\n",
    "\n",
    "cv2.waitKey(0) #Delay. 0 Means Infinite Delay. No. of Milliseconds for which we want to show our image window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ptwtHgkC3lBU",
    "outputId": "974ebffc-6cdb-458b-a84e-55b0f40cbc06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "#Resizing the Image\n",
    "\n",
    "#Reading & Displaying an Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('yourImage.jpg')\n",
    "#Reading an Image\n",
    "\n",
    "cv2.imshow(\"Output\", img) #Displaying the Image\n",
    "\n",
    "print(img.shape) #Shape of the Image (Height, Width, No.of Channels(RGB))\n",
    "\n",
    "cv2.waitKey(0) #Delay. 0 Means Infinite Delay. No. of Milliseconds for which we want to show our image window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ktcqg6TI3lBV"
   },
   "outputs": [],
   "source": [
    "img_resize = cv2.resize(img, (200, 400)) # (Width, Height)\n",
    "\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.imshow(\"Re-sized Image\", img_resize) #Displaying the Image\n",
    "\n",
    "cv2.waitKey(0) #Delay. 0 Means Infinite Delay. If specified 1, it means 1 milliseconds\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pTeRmjEX3lBV",
    "outputId": "973beaf6-4ba6-4e52-c071-14d1dcc30b64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "#Cropping the Image\n",
    "\n",
    "img = cv2.imread('yourImage.jpg') #Reading an Image\n",
    "\n",
    "cv2.imshow(\"Output\", img) #Displaying the Image\n",
    "\n",
    "imgCropped = img[0:200, 200:500] #(Height, Width)\n",
    "\n",
    "cv2.imshow(\"Cropped Image\", imgCropped) #Displaying the Image\n",
    "\n",
    "print(img.shape) #Shape of the Image (Height, Width, No.of Channels(BGR))\n",
    "\n",
    "cv2.waitKey(0) #Delay. 0 Means Infinite Delay. If specified 1, it means 1 milliseconds\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxmfCd5C3lBW"
   },
   "source": [
    "### Shapes and Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ym4uWY7j3lBX",
    "outputId": "70bf4252-f726-4330-ef2d-75fd1e9ffd39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n"
     ]
    }
   ],
   "source": [
    "#0 means Black\n",
    "\n",
    "img = np.zeros((512, 512))#Print a Black Image. It is a GrayScale Image\n",
    "\n",
    "cv2.imshow(\"O\", img)\n",
    "\n",
    "print(img.shape)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "90hzf2KX3lBX"
   },
   "outputs": [],
   "source": [
    "#0 means Black\n",
    "\n",
    "img = np.zeros((512, 512, 3),np.uint8 )#Print a Black Image with 3 Channles RGB.\n",
    "\n",
    "#img[:] = 255, 0 , 0\n",
    "\n",
    "cv2.line(img, (0,0), (300,300), (0,255,255),3) #Staring Pt., Ending Pt., Color, Thickness\n",
    "\n",
    "cv2.imshow(\"O\", img)\n",
    "\n",
    "#print(img.shape)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mvZPkVOn3lBY"
   },
   "outputs": [],
   "source": [
    "cv2.rectangle(img, (0,0), (250,350), (0, 255, 255), cv2.FILLED) #cv2.FILLED is used to Fill the Rectangles\n",
    "\n",
    "cv2.imshow(\"O\", img)\n",
    "\n",
    "#print(img.shape)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uuk5PM9G3lBY"
   },
   "outputs": [],
   "source": [
    "cv2.circle(img, (400,50), 30 , (0, 255, 255), cv2.FILLED) #Center, Radius , Color\n",
    "\n",
    "cv2.imshow(\"O\", img)\n",
    "\n",
    "#print(img.shape)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EfUIZCBc3lBY"
   },
   "outputs": [],
   "source": [
    "cv2.putText(img, \"OpenCV\", (300, 100), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 150,0), 1) #Staring Pt., Font, Scale, Color, Thickness\n",
    "\n",
    "cv2.imshow(\"O\", img)\n",
    "\n",
    "#print(img.shape)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_8kItQi3lBZ"
   },
   "source": [
    "### Joining Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9_mQQGQo3lBZ"
   },
   "outputs": [],
   "source": [
    "#How to Join Image Together\n",
    "\n",
    "img = cv2.imread('yourImage.jpg') #Reading an Image\n",
    "\n",
    "imgHor = np.hstack((img, img))#Images stacked in Horizonatl Direction\n",
    "\n",
    "cv2.imshow(\"Horizontal\", imgHor) #Displaying the Image\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j2D8adIn3lBa"
   },
   "outputs": [],
   "source": [
    "#How to Join Image Together\n",
    "\n",
    "img = cv2.imread('yourImage.jpg') #Reading an Image\n",
    "\n",
    "imgVer = np.vstack((img, img))#Images stacked in Horizonatl Direction\n",
    "\n",
    "cv2.imshow(\"Vertical\", imgVer) #Displaying the Image\n",
    "\n",
    "\n",
    "#Both the Images must have same Channels because they have a matrix and we cannot resize the Images\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JqYRZqTc3lBa"
   },
   "source": [
    "### Face Detection on an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g36ZbdS83lBa"
   },
   "outputs": [],
   "source": [
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "img = cv2.imread('face.jpg') #Reading an Image\n",
    "\n",
    "img = cv2.resize(img, (1240,640))\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = faceCascade.detectMultiScale(imgGray, 1.1, 4)\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x,y),(x+w,y+h),(0,0,255),2)\n",
    "\n",
    "cv2.imshow(\"Output\", img) #Displaying the Image\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPGtiCeX3lBb"
   },
   "source": [
    "### Face Detection in Videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SnNuq2y93lBd"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture('vid.mp4')\n",
    "\n",
    "#Videos are just a sequence of Images\n",
    "#So, we will add a while loop to capture the frame continuously\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    success, frame = cap.read() #frame variable will capture the Video & success variable will tell us whether it was captured successfully or not\n",
    "\n",
    "\n",
    "    imgGray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(imgGray, 1.1, 4)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'): #This adds a Delay and looks for the key press inorder to break the loop\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release() #Release the resources after recording\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y2ECdWBY3lBd"
   },
   "source": [
    "### Face Detection in Real-Time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t13GBden3lBe"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(0) #If you want to display the Video File, just give the name of it inplace of 0\n",
    "\n",
    "#Videos are just a sequence of Images\n",
    "#So, we will add a while loop to capture the frame continuously\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    success, frame = cap.read() #frame variable will capture the Video & success variable will tell us whether it was captured successfully or not\n",
    "\n",
    "\n",
    "    imgGray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(imgGray, 1.1, 4)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x,y),(x+w,y+h),(0,0,255),3)\n",
    "\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'): #This adds a Delay and looks for the key press inorder to break the loop\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release() #Release the resources after recording\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ofF8Wxs43lBe"
   },
   "source": [
    "### Face & Eyes Detection in Real-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ln3hrRUz3lBe"
   },
   "outputs": [],
   "source": [
    "#Face and Eyes Detection in Real-Time\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#Videos are just a sequence of Images\n",
    "#So, we will add a while loop to capture the frame continuously\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_eye.xml\")\n",
    "faceCascade1 = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    success, frame = cap.read() #frame variable will capture the Video & success variable will tell us whether it was captured successfully or not\n",
    "\n",
    "\n",
    "    imgGray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    eyes = faceCascade.detectMultiScale(imgGray, 1.1, 4)\n",
    "    faces = faceCascade1.detectMultiScale(imgGray, 1.1, 4)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x,y),(x+w,y+h),(0,0,0),2)\n",
    "\n",
    "    for (x, y, w, h) in eyes:\n",
    "        cv2.rectangle(frame, (x,y),(x+w,y+h),(0,0,0),2)\n",
    "\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'): #This adds a Delay and looks for the key press inorder to break the loop\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release() #Release the resources after recording\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vgTJFKI3lBf"
   },
   "source": [
    "### Pedestrians Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbYZz7pl3lBf"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('vtest.avi') #note - insert a video link here\n",
    "\n",
    "#Videos are just a sequence of Images\n",
    "#So, we will add a while loop to capture the frame continuously\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_fullbody.xml\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    success, frame = cap.read() #frame variable will capture the Video & success variable will tell us whether it was captured successfully or not\n",
    "\n",
    "\n",
    "    imgGray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(imgGray, 1.1, 4)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x,y),(x+w,y+h),(0,0,0),2)\n",
    "\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'): #This adds a Delay and looks for the key press inorder to break the loop\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release() #Release the resources after recording\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_twVz6AX3lBi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "OpenCV_Basics.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
